{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e4b83df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "import PyPDF2 as pdf\n",
    "from PyPDF2 import PdfReader\n",
    "import re\n",
    "import openai\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "api_key_file = open(\"OPENAI_API_KEY\", \"r\")\n",
    "openai.api_key = api_key_file.read()\n",
    "from openai.embeddings_utils import get_embedding\n",
    "from IPython.display import clear_output\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "def embed(x):\n",
    "    '''embed with openai'''\n",
    "    return get_embedding(x, engine=\"text-embedding-ada-002\")\n",
    "\n",
    "def reset_data():\n",
    "    '''clear all data from directories and json history'''\n",
    "    data_json = {\"stored_pdfs\":{}\n",
    "    }\n",
    "    json_object = json.dumps(data_json, indent=4)\n",
    "    with open(\"Prototype/data_json.json\", \"w\") as outfile:\n",
    "        outfile.write(json_object)  \n",
    "    manual_vectors = pd.DataFrame({\"pdf_id\":[],\"pdf_name\":[],\"avg_embedding\":[]})\n",
    "    manual_vectors.to_pickle('Prototype/vectors/manual_vectors.csv')\n",
    "    folder = \"Prototype/vectors/PageVDs\"\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "\n",
    "def load_pdfs(reset=False):\n",
    "    '''Loads pdfs that have not been loaded into the dataframes. Set reset to True to wipe all data and start again'''\n",
    "    if reset == True:\n",
    "        reset_data()\n",
    "    with open(\"Prototype/data_json.json\", 'r') as openfile:\n",
    "        data_json = json.load(openfile)\n",
    "    pdf_files = os.listdir(\"Prototype/pdf_files\")\n",
    "    max_id = len(data_json.keys())\n",
    "    manual_vectors = pd.read_pickle('Prototype/vectors/manual_vectors.csv')\n",
    "    count = 0\n",
    "    for file in pdf_files:\n",
    "        if file == \".DS_Store\":\n",
    "            continue\n",
    "        \n",
    "        if file not in data_json[\"stored_pdfs\"].values():\n",
    "            count+=1\n",
    "            cur_id = len(data_json[\"stored_pdfs\"].keys())\n",
    "            data_json[\"stored_pdfs\"][cur_id] = file\n",
    "            # PYPDF Part\n",
    "            cur_pdf_text = []\n",
    "            print(f\"processing {file}\")\n",
    "            with open(\"Prototype/pdf_files/\" + file,\"rb\") as pdf_file:\n",
    "                reader = PdfReader(pdf_file)\n",
    "                for j in range(0, len(reader.pages)):\n",
    "                    cur_string = reader.pages[j].extract_text()\n",
    "                    cur_pdf_text.append(\"|start of page {} \".format(j+1)+cur_string + \" end of page {}|\".format(j+1))\n",
    "            page_df = pd.DataFrame({\"pg_no\":list(range(1,len(cur_pdf_text)+1)),\"pg_text\":cur_pdf_text,\"pdf_id\":np.full(len(cur_pdf_text),cur_id)})\n",
    "            print(\"embedding vectors...\")\n",
    "            max_count = len(page_df[\"pg_text\"])\n",
    "            f = IntProgress(min=0, max=max_count)\n",
    "            display(f)\n",
    "            def embed_load(x):\n",
    "                f.value+=1\n",
    "                return embed(x)\n",
    "            page_df[\"pg_embedding\"] = page_df[\"pg_text\"].apply(embed_load)\n",
    "            clear_output()\n",
    "            print(f\"{file} complete!\")\n",
    "            manual_vectors = manual_vectors.append({\"pdf_id\":cur_id,\"pdf_name\":file,\"avg_embedding\":np.array(list(page_df[\"pg_embedding\"])).mean(axis=0)},ignore_index=True)\n",
    "            page_df.to_pickle(f'Prototype/vectors/PageVDs/{cur_id}.csv')\n",
    "            \n",
    "        else:\n",
    "            print(f\"{file} is a duplicate file\")\n",
    "    clear_output()\n",
    "    manual_vectors.to_pickle('Prototype/vectors/manual_vectors.csv')\n",
    "    json_object = json.dumps(data_json, indent=4)\n",
    "    with open(\"Prototype/data_json.json\", \"w\") as outfile:\n",
    "        outfile.write(json_object)\n",
    "    print(f\"added {count} new file(s) to the database\")\n",
    "    \n",
    "def get_suitable_documents(prompt, k_docs=3, details=False):\n",
    "    embedded_prompt = embed(prompt)\n",
    "    manual_df = pd.read_pickle('Prototype/vectors/manual_vectors.csv')\n",
    "    manual_df[\"cos\"] = manual_df[\"avg_embedding\"].apply(lambda x: x@embedded_prompt)\n",
    "    manual_df = manual_df.sort_values(by=\"cos\",ascending=False)\n",
    "    if details == True:\n",
    "        print(\"looking at:\",list(manual_df[\"pdf_name\"])[0:k_docs])\n",
    "    return list(manual_df[\"pdf_id\"][0:k_docs])\n",
    "    \n",
    "    \n",
    "def get_page_text(pdf_id,pg_no):\n",
    "    try:\n",
    "        page_df = pd.read_pickle(f\"Prototype/vectors/PageVDs/{int(pdf_id)}.csv\")\n",
    "        return page_df[page_df[\"pg_no\"] == pg_no].iloc[0][\"pg_text\"]\n",
    "    except:\n",
    "        return \"\"\n",
    "    \n",
    "\n",
    "    \n",
    "def get_suitable_text(prompt,k_docs=8, k_pages=10, details=False):\n",
    "    with open(\"Prototype/data_json.json\", 'r') as openfile:\n",
    "        data_json = json.load(openfile)\n",
    "    #Find suitable manuals\n",
    "    embedded_prompt = embed(prompt)\n",
    "    doc_ids = get_suitable_documents(prompt,k_docs,details)\n",
    "    relevant_df = pd.DataFrame()\n",
    "    for doc_id in doc_ids:\n",
    "        relevant_df = relevant_df.append(pd.read_pickle(f\"Prototype/vectors/PageVDs/{int(doc_id)}.csv\"),ignore_index=True)\n",
    "    #Merge Documents\n",
    "    relevant_df[\"pg_cos\"] = relevant_df[\"pg_embedding\"].apply(lambda x: np.array(x)@embedded_prompt)\n",
    "    ranked_filtered_df = relevant_df.sort_values(by=\"pg_cos\",ascending=False)\n",
    "    idx_pg_pairs = sorted(list(zip(ranked_filtered_df['pdf_id'][0:k_pages],ranked_filtered_df['pg_no'][0:k_pages])))\n",
    "    idx_pg_dict = {}\n",
    "    \n",
    "    for key, value in idx_pg_pairs:\n",
    "        idx_pg_dict.setdefault(key, []).append(value)\n",
    "        \n",
    "    for key,value in idx_pg_dict.items():\n",
    "        page_list = value\n",
    "        new_list = []\n",
    "        for i,page in enumerate(page_list):\n",
    "            if i == len(page_list)-1:\n",
    "                new_list.append(page)\n",
    "                new_list.append(page+1)\n",
    "                break\n",
    "            if (page_list[i+1] - page) >= 4:\n",
    "                new_list.append(page-1)\n",
    "                new_list.append(page)\n",
    "                new_list.append(page+1)\n",
    "            else:\n",
    "                new_list.append(page-1)\n",
    "                for pgno in list(range(page,page_list[i+1])):\n",
    "                    new_list.append(pgno)\n",
    "        idx_pg_dict[key] = list(set([i for i in new_list if i != 0]))\n",
    "    if details == True:\n",
    "        for ID,pages in idx_pg_dict.items():\n",
    "            print(\"pages for {}:\".format(data_json[\"stored_pdfs\"][str(ID)]),pages)\n",
    "    final_list = []\n",
    "    for ID, pages in idx_pg_dict.items():\n",
    "        for page in pages:\n",
    "            final_list.append(get_page_text(ID,page))\n",
    "    return \" \".join(final_list)\n",
    "\n",
    "def chatbot(premise = \"Youâ€™re a technical support bot that has access to manuals. The manual information is here: \",\n",
    "            prompt_mod = \" Notes: You CAN ONLY USE INFO FROM THE MANUAL TEXT I REPEAT.  \\\n",
    "            You CAN ONLY USE INFO FROM THE MANUAL TEXT. If there is nothing available in \\\n",
    "            the text, SAY I don't have the info. Do not generalize answers. Do not state \\\n",
    "            the page numbers. Remember the answers can be from different manuals. Say \\\n",
    "            'According to my resources' if you understand this along with your response\",\n",
    "            \n",
    "            k_docs = 8,\n",
    "            k_pages = 10,\n",
    "            threshold = 0.7,\n",
    "            details = False):\n",
    "    \n",
    "    messages=[\n",
    "    {\"role\": \"system\", \"content\": premise}\n",
    "      ]\n",
    "    response_list = []\n",
    "    \n",
    "    def conversation(response):\n",
    "        if len(messages) == 1:\n",
    "            messages[0][\"content\"] += get_suitable_text(response,k_pages=k_pages,details=details)\n",
    "        response_list.append(response)\n",
    "        content = \"Question: \" + response + prompt_mod\n",
    "        messages.append({\"role\": \"user\", \"content\": content})\n",
    "        \n",
    "        completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-16k-0613\",\n",
    "        messages=messages,\n",
    "        )\n",
    "        message = completion[\"choices\"][0][\"message\"]\n",
    "        chat_response = completion.choices[0].message.content\n",
    "        messages.append({\"role\": \"assistant\", \"content\": chat_response})\n",
    "\n",
    "        return messages\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "    while True:\n",
    "        cur_msg = input(\"Question: \\n\")\n",
    "        if cur_msg == \"exit\":\n",
    "            clear_output()\n",
    "            break\n",
    "        elif cur_msg == \"new\":\n",
    "            clear_output()\n",
    "            messages=[{\"role\": \"system\", \"content\": premise}]\n",
    "        else:\n",
    "            print(\"\\nChatGPT:\")\n",
    "            print(conversation(cur_msg)[-1][\"content\"])\n",
    "            print(\"\\n\")\n",
    "            continue\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1499c6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added 0 new file(s) to the database\n"
     ]
    }
   ],
   "source": [
    "# Add files to pdf_files before running to add new files\n",
    "# Set reset=True to delete all content\n",
    "load_pdfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5daa9f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      "\n",
      "\n",
      "ChatGPT:\n"
     ]
    },
    {
     "ename": "RetryError",
     "evalue": "RetryError[<Future at 0x7f86d0011220 state=finished raised InvalidRequestError>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/embeddings_utils.py\u001b[0m in \u001b[0;36mget_embedding\u001b[0;34m(text, engine, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"embedding\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_resources/embedding.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m         )\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    699\u001b[0m             return (\n\u001b[0;32m--> 700\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    701\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    764\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: '$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9g/btnfbnzs5s98j60gmhcn4fnh0000gn/T/ipykernel_27214/4165796723.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchatbot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_pages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/9g/btnfbnzs5s98j60gmhcn4fnh0000gn/T/ipykernel_27214/360877909.py\u001b[0m in \u001b[0;36mchatbot\u001b[0;34m(premise, prompt_mod, k_docs, k_pages, threshold, details)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nChatGPT:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconversation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"content\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/9g/btnfbnzs5s98j60gmhcn4fnh0000gn/T/ipykernel_27214/360877909.py\u001b[0m in \u001b[0;36mconversation\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconversation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mmessages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"content\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mget_suitable_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk_pages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk_pages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdetails\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdetails\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0mresponse_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Question: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprompt_mod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/9g/btnfbnzs5s98j60gmhcn4fnh0000gn/T/ipykernel_27214/360877909.py\u001b[0m in \u001b[0;36mget_suitable_text\u001b[0;34m(prompt, k_docs, k_pages, details)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mdata_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopenfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;31m#Find suitable manuals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0membedded_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0mdoc_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_suitable_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk_docs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdetails\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mrelevant_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/9g/btnfbnzs5s98j60gmhcn4fnh0000gn/T/ipykernel_27214/360877909.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;34m'''embed with openai'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text-embedding-ada-002\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mretry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetryCallState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRetryError\u001b[0m: RetryError[<Future at 0x7f86d0011220 state=finished raised InvalidRequestError>]"
     ]
    }
   ],
   "source": [
    "chatbot(k_pages = 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
